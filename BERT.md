# BERT: Bidireectional Encoding Representation from Transformers

BERT is perhaps one of the most important large language models (LLMs) ever released.  As the title may suggest, BERT stands for "Bidiretion Encoding Representation from Transformers".  

## Artichecture
Before we discuss what makes BERT special, we should discuss its architecture

## Bidirectionality
The "B" is the most groundbreaking part of BERT, and also what sepatates it from other the other LLMs of its time. 
 



### Sources
https://cloud.google.com/ai-platform/training/docs/algorithms/bert-start#:~:text=BERT%20is%20a%20method%20of,question%20answering%20and%20sentiment%20analysis.
[https://arxiv.org/pdf/1810.04805.pdf](https://arxiv.org/abs/1810.04805)https://arxiv.org/abs/1810.04805

