

Unlimiformer


Summary:

Unlimiformer caches hidden states at each timestep to be stored in a faiss class
for efficient similarity search (?). The index will store all the previous hidden
states that can then be converted to keys and values to be used. At each new timestep,
the queries from each cross attention layer is used to searched for the k most similar
vectors in the index and retrieved to compute cross attention.

Implementation:

The original unlimiformer class is built on top of pretrained model classes such as
BART and LED. The model caches all the encoder hidden states that are then retrieved
during decoder cross attention using queries similarity search.

